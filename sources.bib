
@article{AlphaBetaPruning2022,
  title = {Alpha\textendash Beta Pruning},
  year = {2022},
  month = jan,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Alpha%E2%80%93beta_pruning&oldid=1068746141},
  urldate = {2022-02-01},
  abstract = {Alpha\textendash beta pruning is a search algorithm that seeks to decrease the number of nodes that are evaluated by the minimax algorithm in its search tree. It is an adversarial search algorithm used commonly for machine playing of two-player games (Tic-tac-toe, Chess, Connect 4, etc.). It stops evaluating a move when at least one possibility has been found that proves the move to be worse than a previously examined move. Such moves need not be evaluated further. When applied to a standard minimax tree, it returns the same move as minimax would, but prunes away branches that cannot possibly influence the final decision.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1068746141},
  file = {/home/zjeffer/Documents/Zotero/storage/HY5HATSA/Alpha–beta_pruning.html}
}

@article{AlphaZero2022,
  title = {{{AlphaZero}}},
  year = {2022},
  month = jan,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=AlphaZero&oldid=1065791194},
  urldate = {2022-02-01},
  abstract = {AlphaZero is a computer program developed by artificial intelligence research company DeepMind to master the games of chess, shogi and go.  This algorithm uses an approach similar to AlphaGo Zero.  On December 5, 2017, the DeepMind team released a preprint introducing AlphaZero, which within 24 hours of training achieved a superhuman level of play in these three games by defeating world-champion programs Stockfish, elmo, and the three-day version of AlphaGo Zero. In each case it made use of custom tensor processing units (TPUs) that the Google programs were optimized to use. AlphaZero was trained solely via "self-play" using 5,000 first-generation TPUs to generate the games and 64 second-generation TPUs to train the neural networks, all in parallel, with no access to opening books or endgame tables. After four hours of training, DeepMind estimated AlphaZero was playing chess at a higher Elo rating than Stockfish 8; after nine hours of training, the algorithm defeated Stockfish 8 in a time-controlled 100-game tournament (28 wins, 0 losses, and 72 draws). The trained algorithm played on a single machine with four TPUs.  DeepMind's paper on AlphaZero was published in the journal Science on 7 December 2018. In 2019 DeepMind published a new paper detailing MuZero, a new algorithm able to generalise on AlphaZero work, playing both Atari and board games without knowledge of the rules or representations of the game.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1065791194}
}

@misc{BranchingFactorChessprogramming,
  title = {Branching {{Factor}} - {{Chessprogramming}} Wiki},
  url = {https://www.chessprogramming.org/Branching_Factor},
  urldate = {2022-03-28},
  file = {/home/zjeffer/Documents/Zotero/storage/6PJVRU9Q/Branching_Factor.html}
}

@article{ChessEngine2022,
  title = {Chess Engine},
  year = {2022},
  month = apr,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Chess_engine&oldid=1080874516},
  urldate = {2022-04-05},
  abstract = {In computer chess, a chess engine is a computer program that analyzes chess or chess variant positions, and generates a move or list of moves that it regards as strongest.A chess engine is usually a back end with a command-line interface with no graphics or windowing.  Engines are usually used with a front end, a windowed graphical user interface such as Chessbase or WinBoard that the user can interact with via a keyboard, mouse or touchscreen.  This allows the user to play against multiple engines without learning a new user interface for each, and allows different engines to play against each other. Many chess engines are now available for mobile phones and tablets, making them even more accessible.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1080874516},
  file = {/home/zjeffer/Documents/Zotero/storage/ZNMWQYKQ/Chess_engine.html}
}

@misc{eppesHowComputerizedChess2019,
  title = {How a {{Computerized Chess Opponent}} ``{{Thinks}}'' \textemdash{} {{The Minimax Algorithm}}},
  author = {Eppes, Marissa},
  year = {2019},
  month = oct,
  journal = {Medium},
  url = {https://towardsdatascience.com/how-a-chess-playing-computer-thinks-about-its-next-move-8f028bd0e7b1},
  urldate = {2022-04-05},
  abstract = {In 1997, a computer named ``Deep Blue'' defeated reigning world chess champion Garry Kasparov{$\mkern1mu$}\textemdash{$\mkern1mu$}a defining moment in the history AI theory.},
  langid = {english},
  file = {/home/zjeffer/Documents/Zotero/storage/6HVW2HDS/how-a-chess-playing-computer-thinks-about-its-next-move-8f028bd0e7b1.html}
}

@article{EvaluationFunction2022,
  title = {Evaluation Function},
  year = {2022},
  month = mar,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Evaluation_function&oldid=1079533564},
  urldate = {2022-04-06},
  abstract = {An evaluation function, also known as a heuristic evaluation function or static evaluation function, is a function used by game-playing computer programs to estimate the value or goodness of a position (usually at a leaf or terminal node) in a game tree. Most of the time, the value is either a real number or a quantized integer, often in nths of the value of a playing piece such as a stone in go or a pawn in chess, where n may be tenths, hundredths or other convenient fraction, but sometimes, the value is an array of three values in the unit interval, representing the win, draw, and loss percentages of the position.  There do not exist analytical or theoretical models for evaluation functions for unsolved games, nor are such functions entirely ad-hoc.  The composition of evaluation functions is determined empirically by inserting a candidate function into an automaton and evaluating its subsequent performance.  A significant body of evidence now exists for several games like chess, shogi and go as to the general composition of evaluation functions for them. Games in which game playing computer programs employ evaluation functions include chess, go, shogi (Japanese chess), othello, hex, backgammon, and checkers. In addition, with the advent of programs such as MuZero, computer programs also use evaluation functions to play video games, such as those from the Atari 2600. Some games like tic-tac-toe are strongly solved, and do not require search or evaluation because a discrete solution tree is available.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1079533564},
  file = {/home/zjeffer/Documents/Zotero/storage/H6UN66AT/Evaluation_function.html}
}

@article{GoGame2022,
  title = {Go (Game)},
  year = {2022},
  month = mar,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Go_(game)&oldid=1079941654},
  urldate = {2022-04-06},
  abstract = {Go or Weiqi, Weichi (simplified Chinese: 围棋; traditional Chinese: 圍棋; pinyin: w\'eiq\'i) is an abstract strategy board game for two players in which the aim is to surround more territory than the opponent. The game was invented in China more than 2,500 years ago and is believed to be the oldest board game continuously played to the present day. A 2016 survey by the International Go Federation's 75 member nations found that there are over 46 million people worldwide who know how to play Go and over 20 million current players, the majority of whom live in East Asia.The playing pieces are called stones. One player uses the white stones and the other, black. The players take turns placing the stones on the vacant intersections (points) of a board. Once placed on the board, stones may not be moved, but stones are removed from the board if the stone (or group of stones) is surrounded by opposing stones on all orthogonally adjacent points, in which case the stone or group is captured. The game proceeds until neither player wishes to make another move. When a game concludes, the winner is determined by counting each player's surrounded territory along with captured stones and komi (points added to the score of the player with the white stones as compensation for playing second). Games may also be terminated by resignation. The standard Go board has a 19\texttimes 19 grid of lines, containing 361 points. Beginners often play on smaller 9\texttimes 9 and 13\texttimes 13 boards, and archaeological evidence shows that the game was played in earlier centuries on a board with a 17\texttimes 17 grid. However, boards with a 19\texttimes 19 grid had become standard by the time the game reached Korea in the 5th century CE and Japan in the 7th century CE.Go was considered one of the four essential arts of the cultured aristocratic Chinese scholars in antiquity. The earliest written reference to the game is generally recognized as the historical annal Zuo Zhuan (c. 4th century BCE).Despite its relatively simple rules, Go is extremely complex. Compared to chess, Go has both a larger board with more scope for play and longer games and, on average, many more alternatives to consider per move. The number of legal board positions in Go has been calculated to be approximately 2.1\texttimes 10170, which is vastly greater than the number of atoms in the observable universe, estimated to be of the order of 1080.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1079941654},
  file = {/home/zjeffer/Documents/Zotero/storage/CRB5BTLU/Go_(game).html}
}

@article{Minimax2022,
  title = {Minimax},
  year = {2022},
  month = mar,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Minimax&oldid=1076761456},
  urldate = {2022-04-05},
  abstract = {Minimax (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for minimizing the possible loss for a worst case (maximum loss) scenario.  When dealing with gains, it is referred to as "maximin"\textemdash to maximize the minimum gain.  Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1076761456},
  file = {/home/zjeffer/Documents/Zotero/storage/RV43RPZZ/Minimax.html}
}

@misc{MinimaxMonteCarlo,
  title = {Minimax and {{Monte Carlo Tree Search}} - {{Philipp Muens}}},
  url = {https://philippmuens.com/minimax-and-mcts},
  urldate = {2022-04-06},
  abstract = {Understanding the underpinnings of modern Game AIs.},
  langid = {english},
  file = {/home/zjeffer/Documents/Zotero/storage/I9WAA6KK/minimax-and-mcts.html}
}

@article{MonteCarloTree2022,
  title = {Monte {{Carlo}} Tree Search},
  year = {2022},
  month = apr,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Monte_Carlo_tree_search&oldid=1081107255},
  urldate = {2022-04-06},
  abstract = {In computer science, Monte Carlo tree search (MCTS) is a heuristic search algorithm for some kinds of decision processes, most notably those employed in software that plays board games. In that context MCTS is used to solve the game tree.  MCTS was combined with neural networks in 2016 for computer Go. It has been used in other board games like chess and shogi, games with incomplete information such as bridge and poker, as well as in turn-based-strategy video games (such as Total War: Rome II's implementation in the high level campaign AI). MCTS has also been used in self-driving cars, for example in Tesla's Autopilot software.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1081107255},
  file = {/home/zjeffer/Documents/Zotero/storage/UXBP4BLN/Monte_Carlo_tree_search.html}
}

@article{StockfishChess2022,
  title = {Stockfish (Chess)},
  year = {2022},
  month = mar,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Stockfish_(chess)&oldid=1079146589},
  urldate = {2022-03-28},
  abstract = {Stockfish is a free and open-source chess engine, available for various desktop and mobile platforms. It can be used in chess software through the Universal Chess Interface. Stockfish is consistently ranked first or near the top of most chess-engine rating lists and is the strongest CPU chess engine in the world. It has won the Top Chess Engine Championship 11 times. Stockfish is developed by Marco Costalba, Joona Kiiski, Gary Linscott, Tord Romstad, St\'ephane Nicolet, Stefan Geschwentner, and Joost VandeVondele, with many contributions from a community of open-source developers. It is derived from Glaurung, an open-source engine by Tord Romstad released in 2004.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1079146589},
  file = {/home/zjeffer/Documents/Zotero/storage/FPIS5XAZ/Stockfish_(chess).html}
}


